# FINT-CH Process: Application of pyFINT in the FINT-CH Project

## Overview
The scripts in this folder implement the process for individual tree detection developed in the swiss FINT-CH research project. The process uses pyFINT at its core and sets the filters in pyFINT based on forest structure types. For a description of the process please consult chapter 7.1 of the FINT-CH project report (in German). The process itself is governed by different configuration and data inputs. For its outputs the process relies on a PostgreSQL Database with PostGIS extension for data storage. 

The provided scripts are a slightly cleaned up version of the scripts that were used in the FINT-CH project to perform the area wide detection in the participating cantons. Since these geoprocessing scripts were originally considered as a working tool for automation within a specific environment and dataset, errors are possible with new data or unexpected configurations. The provided files can be divided as follows:
- Common/fintch_utilities.py: A script with helper functions used throughout the FINT-CH project.
- Config/*.*: Files concerning the configuration of the process. Example files for the process are included but need to be modified to suit the respective environment.
- fintch_processing_core.py: This script implements the core logging of the actual process including the derivation of forest structure types, tree detection with pyFINT, generation of combination methods (incorporating detections of multiple filters), and data storage/processing
- fintch_processing_process_kantone.py: This script is responsible for setting up the actual process including configuration, perimeter handling, tiling, and parallelization.

## Prerequisites
### Data
Due to the large data volume and license issues no data from the FINT-CH project is provided. Therefore, the required data must be provided by the user. Note that all geodata is expected to have the same projection. For the FINT-CH project the EPSG 2056/LV95 was used as projection but any other projected coordinate system should work (though the ID generation for the tiles might need to be modified, since it is based on the lower left coordinate of the tile).

#### Perimeter Outlines
The process operates on perimeters whose outlines must be provided in the form of a ESRI shapefile. The file must have a column with a unique ID per perimeter. More than one perimeter may be provided in the same file. However, the perimeters should not overlap to prevent the repeated detection and inclusion of the same tree in the final result. The perimeter doesnâ€™t need to be tiled as the process will automatically generate tiles of 1km2 for parallelization. While the detection of the border tiles may include areas outside the perimeter, only trees within the border are retained. For the FINT-CH project the cantonal borders derived from the swissTLM dataset from swisstopo have been used as perimeter outlines. Other boundary datasets like swissBoundaries3D from swisstopo or perhaps the boundary datasets from BFS Geostat are possible alternatives.

#### Vegetation Height Model
A normalized surface model respectively a Vegetation Height Model (VHM) must be provided as GeoTIFF raster. The VHM is used as input for the actual tree detection. Each perimeter may use a separate VHM raster. VHM with a resolution of 1m derived from ALS data with high point density (&ge;15 points/m2) is recommended as input. Higher resolutions of &lt;1m would work but lower resolutions of &gt;1m would interfere with the filter logic defined in the FINT-CH project.

#### Vegetation Height Model 1.5m
For the derivation of the forest structure type a 1.5m resolution version of the VHM aggregated with the MAX function as GeoTIFF is needed as input. To speed up the process this version of the VHM raster has to be pre-generated and provided as separate input. The aggregation of the VHM to 1.5m resolution can be generated by any GIS software supporting resampling/aggregation of rasters with the MAX function. The use of gdalwarp is recommended. Again, each perimeter may use a separate 1.5m VHM raster.

#### Mixing Degree 10m
The mixing degree with a 10m raster resolution as GeoTIFF is needed as input for the forest structure type derivation. The pixels are expected to have a value between 0 and 10000 encoding the values 0.00% to 100.00%. The NFI Forest mix rate (https://opendata.swiss/en/dataset/waldmischungsgrad-lfi) is a suitable input. Separate rasters per perimeter are possible.

#### Forest Mask
While not strictly necessary, a forest mask should be provided as ESRI shapefile. The mask is used to reduce the detected points to forest areas, thus largely eliminating noise and false positive in non-forest areas. Care has to be taken that the polygon geometries in the forest mask are topologically correct in order to avoid errors in the process. A separate mask per perimeter is possible. As the definition of "forest" may differ from canton to canton, a mask conforming to the definition of the specific application/client should be used. The forest classes of the swissTLM3D ground cover layer may be used as an alternative source. 

#### Power Line Stretches
Optionally a ESRI shapefile with polygons indicating the stretches where powerlines are located can be provided. These polygons are used to eliminate false positives caused by the powerlines and their masts. A separate mask per perimeter is possible.

### Database
The process requires a PostgreSQL database with installed PostGIS extension for storing the detection results. PostgreSQL 10 or higher is recommended. The database, a target schema, and a user need to be manually created and configured beforehand. The user needs privileges to create and delete tables on the target schema. Its credentials along with the database connection information have to be specified in the configuration. The necessary database tables are created by the process itself.

### Environment
The process expects several environment variables pointing to specific locations containing artifacts required by the process.

#### PYFINT_HOME
The PYFINT_HOME environment variable point to the folder containing the pyFINT scripts. The pyFINT module is loaded from that path.

#### FINTCH_HOME
The FINTCH_HOME environment variable point to the folder containing the files connected to the FINT-CH process. That folder is expected to contain the /Common subfolder containing the fintch_utilities.py script. The entire folder is loaded as a module.

#### FINTCH_CONFIG_HOME
This FINTCH_CONFIG_HOME environment variable points to the folder containing FINTCH_config.ini config file.

### Configuration 
#### General Config: FINTCH_config.ini
Part of the process relies on configurations provided by a file called FINTCH_config.ini. Since this file contains sensitive credential information it can be located in a separate location, which is indicated by the FINTCH_CONFIG_HOME environment variable. A sample config file named FINTCH_config_sample.ini is provided with this repository. You are advised to copy this file and modify it to match your environment. The following entries have to be modified:
- result_base_path: Path for temporary files during detection (may need a lot of space depending on the detected area)
- log_path: Path for saving the log file from the process
- crs and epsg: these two entries should be modified such that the EPSG code matches the CRS of the input geodata.
- host, port, dbname, user, password: connection information for the PostgreSQL database used in the process. The user needs to have the right to delete and create tables on the target schema (configured in the main script)

#### Perimeter Config CSV
This file is central for defining the perimeters that are processed by the script. Every row in this CSV represents a perimeter that will be processed. In order to do so, a number of data inputs need to be configured roe each perimeter. This is done using a CSV that is expected to have the following columns:
- Flaeche_ID: Unique ID of the perimeter that will be matched to the perimeter polygon ID
- VHM: Path to the original resolution VHM GeoTIFF raster. 
- Mischungsgrad: Path to the Mixing Degree GeoTIFF raster.
- VHM_150: Path to the 1.5m MAX aggregated VHM GeoTIFF.
- Waldmaske: Path to the forest mask shapefile. Has to have a value if the forest mask is used in the process. 
- Trasse: Path to the shapefile with the power line stretches. Has to have a value if the respective option is used in the process. 

In addition to the configuration in this CSV, each perimeter defined in this file must have a corresponding geometry in the outline shapefile, that will be matched with the value in the Flaeche_ID column.

An example CSV named kantone_info.csv is provided with this repository. note, however, that the simultaneous execution for all cantons would take a considerable amount of time due to the large area and data volume involved. Therefore, the execution in batches (reducing the number of lines in the CSV) is advisable. In this case, the schema or result table prefix needs to be changed for each batch. During the project, each canton was processed in a separate batch. 

#### Configs in main script
Several configurations are made by setting variable values directly in the main script as they may change with each execution:
- flaechen_path: Path to the shapefile with the perimeter outlines
- flaechen_info_path: Path to the CSV with the perimeter configurations
- flaeche_id_column: Name of the unique ID column in the perimeter shapefile
- table_schema: Name of the database schema to create the result tables in. The configured user needs to have the right to create and delete tables in this schema.
- table_base_name: Prefix added to the names of the result tables.
- table_owner: name of the user that is set as owner of the created result tables.
- add_forest_mask: Whether to make use of the forest mask or not.
- add_trasse_mask: Whether to make use of the mask with power line stretches.

Additionally, the num_processes parameter in the process_setup() function calls should be modified to match your system. The parameter indicates the number of processes used for parallelization. The number should not be higher than the number of available cores. For the forest structure derivation more than 15 processes have shown to actually prolong the overall process.

## Usage
The program has been written for Python 3.x. See requirements.txt for dependencies. In the FINT-CH project Python 3.7.x was used. Carefully read the Prerequisites chapter and prepare your environment accordingly. Once the prerequisite configurations are met, the fintch_processing_process_kantone.py can be executed to perform the actual detection. Note that the script deletes existing result tables in the PostgreSQL database. If older results have to be preserved, a different schema or a different table prefix should be used. 

Inputs:
- See Prerequisites

Outputs:
- Database: 
    - &lt;schema&gt;.&lt;prefix&gt;_tree_detected: This table contains the detected trees for all tiles and filter combinations. The trees are already reduced to the forest mask and processed for power line stretches, if the respective options are applicable. This data should be considered a temporary result but may be interesting to compare the results of different filters. 
    - &lt;schema&gt;.&lt;prefix&gt;_perimeter: Contrary to the name this table does not contain the perimeter outlines but the outlines of the individual 1km2 tiles that are used for the actual detections. 
    - &lt;schema&gt;.&lt;prefix&gt;_fst_raster: This table contains a polygon grid with cells of 25m by 25m size with their respective forest structure type. These cells are used to assemble the final result.
    - &lt;schema&gt;.&lt;prefix&gt;_processed_tree: Table with the final result containing the trees picked and combined from the &lt;schema&gt;.&lt;prefix&gt;_tree_detected table based on the forest structure type recorded in the &lt;schema&gt;.&lt;prefix&gt;_fst_raster table. 
- Filesystem: In the folder configured in the result_base_path setting folders for the individual tiles with the raw detection inputs and outputs of pyFINT are created. For the FINT-CH process these are considered temporary files and may be deleted safely if the process has succeeded. 

## Links
- FINT-CH Project Report (in German): https://www.ecorisq.org/relevant-literature/fint/58-final-report-fint-ch-project-in-german/file
- pyFINT download page ecorisQ: https://www.ecorisq.org/ecorisq-tools
